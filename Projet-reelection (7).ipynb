{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import geopandas as gpd\n",
    "import urllib#pour récupérer les données\n",
    "import bs4#pour rendre lisibles les données\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des députés sur le site de l'Assemblée Nationale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrap (url):\n",
    "    req = urllib.request.Request(url)\n",
    "    html = urllib.request.urlopen(req).read()\n",
    "    page = bs4.BeautifulSoup(html, \"lxml\")\n",
    "    return page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ToDf (table) :\n",
    "    Listgrossiere=pd.read_html(str(table))#on transforme le tableau en liste de dataframes\n",
    "    listeDf=Listgrossiere[0]#on récupère le dataframe\n",
    "    return listeDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "page=Scrap('http://www2.assemblee-nationale.fr/sycomore/resultats/(offset)/'+str(0)+'/(query)/IiBTRUxFQ1QgbV9jb2RlX2RlcHV0ZSwgaWRfYWN0ZXVyX3RyaWJ1biwgbGVnX21heF90cmlidW4sIG5vbSwgbm9tX2FmZmljaGUsIHByZW5vbSwgZGF0ZV9uYWlzLCBkYXRlX2RlY2VzIEZST00gZGVwdXRlIFdIRVJFIDE9MSAgQU5EIG1fY29kZV9kZXB1dGUgSU4gKFNFTEVDVCBtX2NvZGVfZGVwdXRlIEZST00gbWFuZGF0LCBkZXBhcnRlbWVudCAgV0hFUkUgbWFuZGF0Lm1fbnVtX2RlcCA9IGRlcGFydGVtZW50Lm1fbnVtX2RlcCBBTkQgbWFuZGF0Lm1fdHlwZV9tYW5kYXQgPSAxICkgT1JERVIgQlkgZGF0ZV9uYWlzIERFU0Mi')\n",
    "table = page.find('table')\n",
    "liste=ToDf(table)\n",
    "for i in range(32):\n",
    "    page=Scrap('http://www2.assemblee-nationale.fr/sycomore/resultats/(offset)/'+str((i+1)*500)+'/(query)/IiBTRUxFQ1QgbV9jb2RlX2RlcHV0ZSwgaWRfYWN0ZXVyX3RyaWJ1biwgbGVnX21heF90cmlidW4sIG5vbSwgbm9tX2FmZmljaGUsIHByZW5vbSwgZGF0ZV9uYWlzLCBkYXRlX2RlY2VzIEZST00gZGVwdXRlIFdIRVJFIDE9MSAgQU5EIG1fY29kZV9kZXB1dGUgSU4gKFNFTEVDVCBtX2NvZGVfZGVwdXRlIEZST00gbWFuZGF0LCBkZXBhcnRlbWVudCAgV0hFUkUgbWFuZGF0Lm1fbnVtX2RlcCA9IGRlcGFydGVtZW50Lm1fbnVtX2RlcCBBTkQgbWFuZGF0Lm1fdHlwZV9tYW5kYXQgPSAxICkgT1JERVIgQlkgZGF0ZV9uYWlzIERFU0Mi')\n",
    "    table = page.find('table')#on récupère le seul tableau de la page qui liste des députés\n",
    "    listeDf=ToDf(table)\n",
    "    liste=pd.concat([liste,listeDf])#on récupère le dataframe et on l'ajoute à la liste\n",
    "    \n",
    "liste=liste.reset_index()#on recrée un index afin de ne pas s'arrêter à 500 puis recommencer comme dans les pages web\n",
    "listeDepute=liste[['Nom','Né le']]#on récupère les variables qui nous intéressent  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On s'intéresse ensuite à la récupération des mandats de chaque député (partie en cours)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_un_mandat(mandat):\n",
    "    #On récupère et lave les titres des colonnes\n",
    "    columns=mandat.findAll('dt')\n",
    "    columns=re.sub('<[^<]+?>', '', str(columns))  \n",
    "    \n",
    "    #On récupère et lave les titres des lignes\n",
    "    lines=mandat.findAll('dd')\n",
    "    lines=re.sub('<[^<]+?>', '', str(lines))\n",
    "    lines=re.sub('\\t', '', str(lines))\n",
    "    lines=re.sub(\"\\n\", '', str(lines))\n",
    "    line=''\n",
    "    \n",
    "    #On met tout dans un dataframe\n",
    "    columns=columns[1:-1].split(',')\n",
    "    lines=lines[1:-1].split(',')\n",
    "    df=pd.DataFrame([lines],columns=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RecupNom (page):\n",
    "    nom_depute=page.find('title')#on va là où il y a le nom\n",
    "    nom_depute=re.sub('<[^<]+?>', '', str(nom_depute))#on enlève les balises\n",
    "    nom_depute=nom_depute.split()#on récupère les mots du titre\n",
    "    mot=nom_depute[0]#on initialise au premier mot\n",
    "    nom_dep=''#on initialise la variable où on va récupérer le nom\n",
    "    while mot!='-' :#on prend les premiers mots qui composent le nom, avant la suite du titre\n",
    "        nom_dep=nom_dep+' '+mot#on concatène le mot appartenant au nom avec les précédents\n",
    "        nom_depute=nom_depute[1:]#on supprime le mot étudié\n",
    "        mot=nom_depute[0]#pour passer au suivant\n",
    "    return nom_dep#on retourne le mot complet. Il est surement possible de le faire beaucoup plus vite en regex, mais les miennes ne marchent pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sylva\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tps1=time.time()\n",
    "page=Scrap('http://www2.assemblee-nationale.fr/sycomore/fiche/(num_dept)/'+str(5))\n",
    "listeMandat=page\n",
    "liste=[]\n",
    "numProbleme=[]\n",
    "for i in range(5,19501) :\n",
    "    page=Scrap('http://www2.assemblee-nationale.fr/sycomore/fiche/(num_dept)/'+str(i+7))\n",
    "    #Une petite blague c'est glissé dans le site : les mandats de sénateurs sont présent dans le code html mais ils sont \"cachés\"\n",
    "    #On les enlève donc d'abord\n",
    "    pouf=page.find('div', {'id':\"mandats_an\"})\n",
    "    if pouf :\n",
    "        depute=pouf.findAll('dl', {'class' : \"deputes-liste-attributs sycomore\"})\n",
    "    else :#éviter les cas d'assemblée nationale constituante qui ont un autre nom que mandats_an\n",
    "        depute=page.findAll('dl', {'class' : \"deputes-liste-attributs sycomore\"})\n",
    "    for mandat in depute :\n",
    "        try:\n",
    "            df = scrap_un_mandat(mandat)\n",
    "        except AssertionError :\n",
    "            numProbleme.append(i)\n",
    "        else :#ne marche pas en elif ! A cause du try\n",
    "            df[\"nom du député\"]=RecupNom(page)\n",
    "            if len(liste)==0: #On initialise avec le premier mandat\n",
    "                liste=df  \n",
    "            else:\n",
    "                liste=pd.concat([liste,df])#on fusionne les mandats\n",
    "print(len(numProbleme))\n",
    "tps2=time.time()\n",
    "print(\"temps d'exécution\",tps2-tps1)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y des pages de députés jusqu'à 19500 sur le site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste.to_csv(r'C:\\Users\\sylva\\Desktop\\git\\Projet-Python-deputes\\liste_mandat.csv')\n",
    "#on met les données sur csv pour ne pas avoir à rescrapper à chaque fois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(liste)/len(numProbleme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
