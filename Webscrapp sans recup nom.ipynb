{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import geopandas as gpd\n",
    "import urllib#pour récupérer les données\n",
    "import bs4#pour rendre lisibles les données\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des députés sur le site de l'Assemblée Nationale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrap (url):\n",
    "    req = urllib.request.Request(url)\n",
    "    html = urllib.request.urlopen(req).read()\n",
    "    page = bs4.BeautifulSoup(html, \"lxml\")\n",
    "    return page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ToDf (table) :\n",
    "    Listgrossiere=pd.read_html(str(table))#on transforme le tableau en liste de dataframes\n",
    "    listeDf=Listgrossiere[0]#on récupère le dataframe\n",
    "    return listeDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "page=Scrap('http://www2.assemblee-nationale.fr/sycomore/resultats/(offset)/'+str(0)+'/(query)/IiBTRUxFQ1QgbV9jb2RlX2RlcHV0ZSwgaWRfYWN0ZXVyX3RyaWJ1biwgbGVnX21heF90cmlidW4sIG5vbSwgbm9tX2FmZmljaGUsIHByZW5vbSwgZGF0ZV9uYWlzLCBkYXRlX2RlY2VzIEZST00gZGVwdXRlIFdIRVJFIDE9MSAgQU5EIG1fY29kZV9kZXB1dGUgSU4gKFNFTEVDVCBtX2NvZGVfZGVwdXRlIEZST00gbWFuZGF0LCBkZXBhcnRlbWVudCAgV0hFUkUgbWFuZGF0Lm1fbnVtX2RlcCA9IGRlcGFydGVtZW50Lm1fbnVtX2RlcCBBTkQgbWFuZGF0Lm1fdHlwZV9tYW5kYXQgPSAxICkgT1JERVIgQlkgZGF0ZV9uYWlzIERFU0Mi')\n",
    "table = page.find('table')\n",
    "liste=ToDf(table)\n",
    "listelien=[]\n",
    "for i in range(32):\n",
    "    page=Scrap('http://www2.assemblee-nationale.fr/sycomore/resultats/(offset)/'+str((i+1)*500)+'/(query)/IiBTRUxFQ1QgbV9jb2RlX2RlcHV0ZSwgaWRfYWN0ZXVyX3RyaWJ1biwgbGVnX21heF90cmlidW4sIG5vbSwgbm9tX2FmZmljaGUsIHByZW5vbSwgZGF0ZV9uYWlzLCBkYXRlX2RlY2VzIEZST00gZGVwdXRlIFdIRVJFIDE9MSAgQU5EIG1fY29kZV9kZXB1dGUgSU4gKFNFTEVDVCBtX2NvZGVfZGVwdXRlIEZST00gbWFuZGF0LCBkZXBhcnRlbWVudCAgV0hFUkUgbWFuZGF0Lm1fbnVtX2RlcCA9IGRlcGFydGVtZW50Lm1fbnVtX2RlcCBBTkQgbWFuZGF0Lm1fdHlwZV9tYW5kYXQgPSAxICkgT1JERVIgQlkgZGF0ZV9uYWlzIERFU0Mi')\n",
    "    table = page.find('table')#on récupère le seul tableau de la page qui liste des députés\n",
    "    listeDf=ToDf(table)\n",
    "    liste=pd.concat([liste,listeDf])#on récupère le dataframe et on l'ajoute à la liste  \n",
    "    for ele in table.findAll('a'):\n",
    "        listelien.append(ele.get('href'))\n",
    "liste=liste.reset_index()#on recrée un index afin de ne pas s'arrêter à 500 puis recommencer comme dans les pages web\n",
    "listeDepute=liste[['Nom','Né le']]#on récupère les variables qui nous intéressent  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15860"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listelien)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/sycomore/fiche/(num_dept)/18458'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listelien[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "listeDepute.to_csv(r'C:\\Users\\sylva\\Desktop\\git\\Projet-Python-deputes\\liste_depute.csv')#on met les données sur csv pour ne pas avoir à rescrapper à chaque fois"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On s'intéresse ensuite à la récupération des mandats de chaque député (partie en cours)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recup_dep_naiss (page):\n",
    "    depute_naiss=page.findAll('dl', {'class' : \"deputes-liste-attributs sycomore-infos-generales\"})\n",
    "    dep_naiss=re.findall('\\((\\w*-?\\w*)\\s', str(depute_naiss))#on récupère les départements\n",
    "    if dep_naiss==['']:\n",
    "        dep_naiss=['Inconnu']\n",
    "    df_naissance=pd.DataFrame([['Inconnu', 'Inconnu']], columns=('Département de naissance', 'Département de mort'))\n",
    "    if dep_naiss :\n",
    "        if len(dep_naiss)==2 :#on connait plus les départements de naissance que les morts (pour les députés vivants au moins)\n",
    "            df_naissance=pd.DataFrame([dep_naiss], columns=('Département de naissance', 'Département de mort'))\n",
    "        elif len(dep_naiss)==1 :\n",
    "            dep_complete=[dep_naiss[0],'Inconnu']\n",
    "            df_naissance=pd.DataFrame([dep_complete], columns=('Département de naissance', 'Département de mort'))\n",
    "       \n",
    "    return(df_naissance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_un_mandat(mandat):\n",
    "    #On récupère et lave les titres des colonnes\n",
    "    columns=mandat.findAll('dt')\n",
    "    columns=re.sub('<[^<]+?>', '', str(columns))  \n",
    "    \n",
    "    #On récupère et lave les titres des lignes\n",
    "    lines=mandat.findAll('dd')\n",
    "    lines=re.sub('<[^<]+?>', '', str(lines))\n",
    "    lines=re.sub('\\t', '', str(lines))\n",
    "    lines=re.sub(\"\\n\", '', str(lines))\n",
    "   \n",
    "        \n",
    "    \n",
    "    \n",
    "    #On met tout dans un dataframe\n",
    "    columns=columns[1:-1].split(',')\n",
    "    lines=lines[1:-1].split(',')\n",
    "    if len(lines)>5:\n",
    "        lines=lines[:5]\n",
    "    df=pd.DataFrame([lines],columns=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RecupNom (page):\n",
    "    nom_depute=page.find('title')#on va là où il y a le nom\n",
    "    nom_depute=re.sub('<[^<]+?>', '', str(nom_depute))#on enlève les balises\n",
    "    nom_depute=nom_depute.split()#on récupère les mots du titre\n",
    "    mot=nom_depute[0]#on initialise au premier mot\n",
    "    nom_dep=''#on initialise la variable où on va récupérer le nom\n",
    "    while mot!='-' :#on prend les premiers mots qui composent le nom, avant la suite du titre\n",
    "        nom_dep=nom_dep+' '+mot#on concatène le mot appartenant au nom avec les précédents\n",
    "        nom_depute=nom_depute[1:]#on supprime le mot étudié\n",
    "        mot=nom_depute[0]#pour passer au suivant\n",
    "    nom_dep=nom_dep[1:]#il y a un espace au début, on l'enlève\n",
    "    return nom_dep#on retourne le mot complet. Il est surement possible de le faire beaucoup plus vite en regex, mais les miennes ne marchent pas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette proposition permet de se passer de RecupNom mais il y a encore des bugs : \n",
    "Attention !!!!!!!!!!!!!!!!!!!!!!! La listeDepute n'est pas dans le même ordre que la liste en ligne, donc cela n'attribue pas le nom au bon député ! (d'où le retour à RécupNom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tps1=time.time()\n",
    "liste=[]\n",
    "numProbleme=[]\n",
    "df_naiss=[]\n",
    "for i in range(0,len(listelien) ) : \n",
    "    if i%100==1 :#pour mesurer l'avancement du scrapping\n",
    "        print(i)\n",
    "    page=Scrap('http://www2.assemblee-nationale.fr/'+listelien[i])\n",
    "    #Une petite blague c'est glissé dans le site : les mandats de sénateurs sont présent dans le code html mais ils sont \"cachés\"\n",
    "    #On les enlève donc d'abord\n",
    "    pouf=page.find('div', {'id':\"mandats_an\"})\n",
    "    df_naissance=recup_dep_naiss(page)#on récupère d'abord les départements de naissance et de mort du député    \n",
    "    df_naissance['Nom']=RecupNom(page)\n",
    "    if len(df_naiss)==0:\n",
    "        df_naiss=df_naissance\n",
    "    else :\n",
    "        df_naiss=pd.concat([df_naiss, df_naissance])\n",
    "    if pouf :\n",
    "        depute=pouf.findAll('dl', {'class' : \"deputes-liste-attributs sycomore\"})\n",
    "    else :#éviter les cas d'assemblée nationale constituante qui ont un autre nom que mandats_an\n",
    "        depute=page.findAll('dl', {'class' : \"deputes-liste-attributs sycomore\"})\n",
    "    for mandat in depute :   \n",
    "        try:\n",
    "            df = scrap_un_mandat(mandat)\n",
    "        except AssertionError :\n",
    "            print('http://www2.assemblee-nationale.fr/'+listelien[i])\n",
    "            numProbleme.append(i)\n",
    "        else :#ne marche pas en elif ! A cause du try\n",
    "            df['Nom']=RecupNom(page)            \n",
    "            if len(liste)==0: #On initialise avec le premier mandat\n",
    "                liste=df                  \n",
    "            else:\n",
    "                liste=pd.concat([liste,df])#on fusionne les mandats\n",
    "                \n",
    "tps2=time.time()  \n",
    "tps=tps2-tps1    \n",
    "print(len(numProbleme))\n",
    "print(\"temps d'exécution\",tps)   \n",
    "display(liste.head(5))\n",
    "df_naiss.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y des pages de députés jusqu'à 19500 sur le site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On joint les deux dataframes ayant des informations personnelles sur les députés\n",
    "listeDepu=listeDepute.copy()\n",
    "df_naiss2=df_naiss.copy()\n",
    "listeDepute_complete=listeDepu.merge(df_naiss2, on='Nom', how='outer')\n",
    "\n",
    "#Cette ligne va créer des problèmes car plusieurs députés ont le même nom,\n",
    "#ainsi, plusieurs député vont avoir des dpt de naissance similaires alors que c'est faux\n",
    "listeDepute_complete.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste=liste.rename(columns={' Département': 'Département', ' Groupe': 'Groupe', ' Législature': 'Législature', ' Mandat' :'Mandat'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_dep=liste[['Département', 'Groupe', 'Législature', 'Mandat', 'Régime politique', 'Nom']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(liste)/len(numProbleme)#un indicateur du nombre de problèmes, pour vérifier que les résultats sont encore significatifs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Formatage des dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_dep.to_csv(r'C:\\Users\\sylva\\Desktop\\git\\Projet-Python-deputes\\liste_mandat.csv')\n",
    "listeDepute_complete.to_csv(r'C:\\Users\\sylva\\Desktop\\git\\Projet-Python-deputes\\listeDepute_complete.csv')\n",
    "#on met les données sur csv pour ne pas avoir à rescrapper à chaque fois"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
